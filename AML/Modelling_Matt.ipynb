{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Notebook - Matt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import HelperFunctions as hf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the raw data\n",
    "calendar_df = hf.load_calendar_data()\n",
    "prices_df = hf.load_sell_price_data()\n",
    "sales_df = hf.load_sales_train_validation_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the raw data\n",
    "df = hf.rawToClean(sales_df, calendar_df, prices_df, days=1200, items=1000, dropNAPrices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf.priceDifference(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf.rollingPriceDifference(df, windowsize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf.rollingMeanDemandFeature(df, windowSize=7, shift=1)#Mean of previous week\n",
    "df = hf.rollingMeanDemandFeature(df, windowSize=14, shift=1)\n",
    "df = hf.rollingMeanDemandFeature(df, windowSize=28, shift=1) #Mean of previous 28 days\n",
    "df = hf.rollingMeanDemandFeature(df, windowSize=7, shift=7)\n",
    "df = hf.rollingMeanDemandFeature(df, windowSize=7, shift=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf.rollingStdDemandFeature(df, windowSize=7, shift=1)\n",
    "df = hf.rollingStdDemandFeature(df, windowSize=14, shift=1)\n",
    "df = hf.rollingStdDemandFeature(df, windowSize=28, shift=1)\n",
    "df = hf.rollingStdDemandFeature(df, windowSize=7, shift=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattwear/GroupWork/AML/HelperFunctions.py:230: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  data = pd.concat([data, d])\n"
     ]
    }
   ],
   "source": [
    "df = hf.rollingMeanWeekday(df, weeks = 3, shift = 1) #mean of previous 3 weeks (for that particular weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf.lagFeature(df, var='sold', lag=1) #Amount sold day before\n",
    "df = hf.lagFeature(df, var='sold', lag=7) #Amount sold a week before\n",
    "df = hf.lagFeature(df, var='sold', lag=14)\n",
    "df = hf.lagFeature(df, var='sold', lag=28) #Amount sold 28 days before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True) #Drop rows with NAs (as result of lagged features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product_ids = df.id.copy()\n",
    "df.drop(['id'], axis=1, inplace=True) #Drop the id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d              0\n",
       "sold           0\n",
       "wday           0\n",
       "month          0\n",
       "year           0\n",
       "snap_CA        0\n",
       "snap_TX        0\n",
       "snap_WI        0\n",
       "sell_price     0\n",
       "Cultural       0\n",
       "National       0\n",
       "Religious      0\n",
       "Sporting       0\n",
       "NoEvent        0\n",
       "Christmas      0\n",
       "weekend        0\n",
       "midweek        0\n",
       "monfri         0\n",
       "FOODS_1        0\n",
       "FOODS_2        0\n",
       "FOODS_3        0\n",
       "HOBBIES_1      0\n",
       "HOBBIES_2      0\n",
       "HOUSEHOLD_1    0\n",
       "HOUSEHOLD_2    0\n",
       "FOODS          0\n",
       "HOBBIES        0\n",
       "HOUSEHOLD      0\n",
       "CA_1           0\n",
       "CA_2           0\n",
       "CA_3           0\n",
       "CA_4           0\n",
       "TX_1           0\n",
       "TX_2           0\n",
       "TX_3           0\n",
       "WI_1           0\n",
       "WI_2           0\n",
       "WI_3           0\n",
       "CA             0\n",
       "TX             0\n",
       "WI             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808600, 41)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['d', 'sold', 'wday', 'month', 'year', 'snap_CA', 'snap_TX', 'snap_WI',\n",
       "       'sell_price', 'Cultural', 'National', 'Religious', 'Sporting',\n",
       "       'NoEvent', 'Christmas', 'weekend', 'midweek', 'monfri', 'FOODS_1',\n",
       "       'FOODS_2', 'FOODS_3', 'HOBBIES_1', 'HOBBIES_2', 'HOUSEHOLD_1',\n",
       "       'HOUSEHOLD_2', 'FOODS', 'HOBBIES', 'HOUSEHOLD', 'CA_1', 'CA_2', 'CA_3',\n",
       "       'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3', 'CA', 'TX',\n",
       "       'WI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "We also isolate the target variables from the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardise features\n",
    "cols_to_norm = ['d','wday','month','year','sell_price','rolling_mean_7_1','rolling_mean_14_1','rolling_mean_28_1','rolling_mean_7_7','rolling_mean_7_28','sold_lag_1',\n",
    "                'sold_lag_7','sold_lag_14','sold_lag_28','rolling_std_7_1','rolling_std_14_1','rolling_std_28_1',\n",
    "               'rolling_std_7_28','price_diff']\n",
    "\n",
    "cols_to_norm = ['d','wday','month','year','sell_price']\n",
    "\n",
    "df[cols_to_norm] = MinMaxScaler().fit_transform(df[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate features and target variable\n",
    "y = df.sold.values\n",
    "X_df = df.drop(['sold'], axis=1)\n",
    "X = X_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3217325, 40)\n",
      "(3217325,)\n",
      "(804332, 40)\n",
      "(804332,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "The results of fitting a linear regression model on the data and analysing the feature's p-values raises some interesting findings. \n",
    "* Amongst the event related features only cultural and xmas are significant. As expected, Xmas is the most influential feature of them all.  \n",
    "* The LR also confirms our findings in analysis that weekend/monfri/midweek are all significant features for predicting sales volume. \n",
    "* CA_4 and CA_3 is the only store that is an insignificant predictor. Perhaps higher population in this area?\n",
    "* The mean of sold items in the week leading up is the second most influential feature.\n",
    "* More expensive items sell in lower quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   sold   R-squared:                       0.090\n",
      "Model:                            OLS   Adj. R-squared:                  0.090\n",
      "Method:                 Least Squares   F-statistic:                     2566.\n",
      "Date:                Mon, 29 Mar 2021   Prob (F-statistic):               0.00\n",
      "Time:                        14:12:42   Log-Likelihood:            -2.2468e+06\n",
      "No. Observations:              808600   AIC:                         4.494e+06\n",
      "Df Residuals:                  808568   BIC:                         4.494e+06\n",
      "Df Model:                          31                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "d              -8.9833      1.224     -7.336      0.000     -11.383      -6.583\n",
      "wday            0.0519      0.021      2.419      0.016       0.010       0.094\n",
      "month           2.3563      0.342      6.880      0.000       1.685       3.028\n",
      "year            7.7627      1.119      6.934      0.000       5.569       9.957\n",
      "snap_CA        -0.0192      0.016     -1.192      0.233      -0.051       0.012\n",
      "snap_TX         0.0491      0.012      4.008      0.000       0.025       0.073\n",
      "snap_WI         0.1043      0.012      8.743      0.000       0.081       0.128\n",
      "sell_price     -4.1334      0.030   -139.366      0.000      -4.192      -4.075\n",
      "Cultural       -0.2448      0.088     -2.781      0.005      -0.417      -0.072\n",
      "National       -0.1220      0.098     -1.251      0.211      -0.313       0.069\n",
      "Religious      -0.0254      0.089     -0.284      0.777      -0.201       0.150\n",
      "Sporting       -0.0208      0.105     -0.198      0.843      -0.227       0.186\n",
      "NoEvent        -0.0323      0.093     -0.346      0.729      -0.215       0.151\n",
      "Christmas      -1.2319      0.090    -13.628      0.000      -1.409      -1.055\n",
      "weekend         0.8725      0.027     32.156      0.000       0.819       0.926\n",
      "midweek         0.3877      0.026     14.692      0.000       0.336       0.439\n",
      "monfri          0.5268      0.027     19.680      0.000       0.474       0.579\n",
      "FOODS_1        -0.6620      0.015    -44.268      0.000      -0.691      -0.633\n",
      "FOODS_2         0.5421      0.014     40.021      0.000       0.516       0.569\n",
      "FOODS_3         1.1942      0.013     95.157      0.000       1.170       1.219\n",
      "HOBBIES_1       0.8890      0.016     54.606      0.000       0.857       0.921\n",
      "HOBBIES_2      -0.6512      0.019    -35.060      0.000      -0.688      -0.615\n",
      "HOUSEHOLD_1     0.6731      0.014     47.344      0.000       0.645       0.701\n",
      "HOUSEHOLD_2    -0.1981      0.014    -13.784      0.000      -0.226      -0.170\n",
      "FOODS           1.0743      0.028     38.847      0.000       1.020       1.128\n",
      "HOBBIES         0.2378      0.025      9.446      0.000       0.188       0.287\n",
      "HOUSEHOLD       0.4750      0.025     19.230      0.000       0.427       0.523\n",
      "CA_1           -0.2594      0.014    -18.315      0.000      -0.287      -0.232\n",
      "CA_2            0.1217      0.014      8.460      0.000       0.093       0.150\n",
      "CA_3            0.9133      0.013     69.220      0.000       0.887       0.939\n",
      "CA_4           -0.1334      0.013    -10.082      0.000      -0.159      -0.107\n",
      "TX_1           -0.3468      0.014    -24.937      0.000      -0.374      -0.320\n",
      "TX_2            0.2756      0.014     19.467      0.000       0.248       0.303\n",
      "TX_3            0.5365      0.014     38.357      0.000       0.509       0.564\n",
      "WI_1            0.0492      0.015      3.374      0.001       0.021       0.078\n",
      "WI_2            0.9351      0.014     67.700      0.000       0.908       0.962\n",
      "WI_3           -0.3049      0.014    -21.770      0.000      -0.332      -0.277\n",
      "CA              0.6422      0.027     23.967      0.000       0.590       0.695\n",
      "TX              0.4654      0.025     18.445      0.000       0.416       0.515\n",
      "WI              0.6795      0.025     26.871      0.000       0.630       0.729\n",
      "==============================================================================\n",
      "Omnibus:                  1218348.043   Durbin-Watson:                   2.003\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       1199494780.993\n",
      "Skew:                           9.088   Prob(JB):                         0.00\n",
      "Kurtosis:                     190.808   Cond. No.                     5.20e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.09e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(df['sold'], df[X_df.columns])\n",
    "#mod = sm.OLS(y_train, X_train)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snap_CA</td>\n",
       "      <td>0.019191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sporting</td>\n",
       "      <td>0.020822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Religious</td>\n",
       "      <td>0.025353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.032322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snap_TX</td>\n",
       "      <td>0.049111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WI_1</td>\n",
       "      <td>0.049244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wday</td>\n",
       "      <td>0.051864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>snap_WI</td>\n",
       "      <td>0.104337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CA_2</td>\n",
       "      <td>0.121662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>National</td>\n",
       "      <td>0.122007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>0.133364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>0.198105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0.237764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cultural</td>\n",
       "      <td>0.244819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>0.259356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TX_2</td>\n",
       "      <td>0.275635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WI_3</td>\n",
       "      <td>0.304866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>0.346776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>midweek</td>\n",
       "      <td>0.387707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TX</td>\n",
       "      <td>0.465409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.475013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>monfri</td>\n",
       "      <td>0.526844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TX_3</td>\n",
       "      <td>0.536550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>0.542074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CA</td>\n",
       "      <td>0.642196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>0.651226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>0.661954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>0.673118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>WI</td>\n",
       "      <td>0.679455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>weekend</td>\n",
       "      <td>0.872508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>0.888990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>0.913254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>WI_2</td>\n",
       "      <td>0.935077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>1.074282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>1.194162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Christmas</td>\n",
       "      <td>1.231853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>month</td>\n",
       "      <td>2.356343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sell_price</td>\n",
       "      <td>4.133406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>year</td>\n",
       "      <td>7.762680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>d</td>\n",
       "      <td>8.983342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "0       snap_CA    0.019191\n",
       "1      Sporting    0.020822\n",
       "2     Religious    0.025353\n",
       "3       NoEvent    0.032322\n",
       "4       snap_TX    0.049111\n",
       "5          WI_1    0.049244\n",
       "6          wday    0.051864\n",
       "7       snap_WI    0.104337\n",
       "8          CA_2    0.121662\n",
       "9      National    0.122007\n",
       "10         CA_4    0.133364\n",
       "11  HOUSEHOLD_2    0.198105\n",
       "12      HOBBIES    0.237764\n",
       "13     Cultural    0.244819\n",
       "14         CA_1    0.259356\n",
       "15         TX_2    0.275635\n",
       "16         WI_3    0.304866\n",
       "17         TX_1    0.346776\n",
       "18      midweek    0.387707\n",
       "19           TX    0.465409\n",
       "20    HOUSEHOLD    0.475013\n",
       "21       monfri    0.526844\n",
       "22         TX_3    0.536550\n",
       "23      FOODS_2    0.542074\n",
       "24           CA    0.642196\n",
       "25    HOBBIES_2    0.651226\n",
       "26      FOODS_1    0.661954\n",
       "27  HOUSEHOLD_1    0.673118\n",
       "28           WI    0.679455\n",
       "29      weekend    0.872508\n",
       "30    HOBBIES_1    0.888990\n",
       "31         CA_3    0.913254\n",
       "32         WI_2    0.935077\n",
       "33        FOODS    1.074282\n",
       "34      FOODS_3    1.194162\n",
       "35    Christmas    1.231853\n",
       "36        month    2.356343\n",
       "37   sell_price    4.133406\n",
       "38         year    7.762680\n",
       "39            d    8.983342"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_feature_imp = pd.DataFrame(res.params).reset_index()\n",
    "lr_feature_imp.columns = ['feature','importance']\n",
    "lr_feature_imp.importance = np.absolute(lr_feature_imp.importance)\n",
    "lr_feature_imp = lr_feature_imp.sort_values(by=['importance'], ascending=True).reset_index(drop=True)\n",
    "lr_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Train test split\n",
    "###Normalise features\n",
    "###More Data Analysis\n",
    "###Feature Extraction - average of weekday - exponential averages - Eve Events\n",
    "###Modelling\n",
    "###Feature selection - Linear Regression/RandomForests/Lasso/Correlation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression - Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dc = DecisionTreeRegressor(max_depth=10, random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(df.columns)\n",
    "features = np.delete(features, [1])\n",
    "feature_imp = pd.DataFrame({'feature': features, 'importance': dc.feature_importances_})\n",
    "feature_imp = feature_imp.sort_values(by=['importance'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Christmas</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sporting</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoEvent</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Religious</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>monfri</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>midweek</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cultural</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>National</td>\n",
       "      <td>0.000472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>0.000478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>snap_CA</td>\n",
       "      <td>0.001049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>0.001579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>0.002172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>snap_TX</td>\n",
       "      <td>0.002337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TX_2</td>\n",
       "      <td>0.002349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>weekend</td>\n",
       "      <td>0.002387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>year</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WI_3</td>\n",
       "      <td>0.004111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>WI</td>\n",
       "      <td>0.004487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TX_3</td>\n",
       "      <td>0.006562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>wday</td>\n",
       "      <td>0.008980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>0.011794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>0.011983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TX</td>\n",
       "      <td>0.014334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>0.014792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CA_2</td>\n",
       "      <td>0.015304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>WI_1</td>\n",
       "      <td>0.015749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>month</td>\n",
       "      <td>0.016901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>snap_WI</td>\n",
       "      <td>0.021974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>0.023086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>0.026263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>WI_2</td>\n",
       "      <td>0.046776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>CA</td>\n",
       "      <td>0.062013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FOODS</td>\n",
       "      <td>0.069010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>d</td>\n",
       "      <td>0.139118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sell_price</td>\n",
       "      <td>0.467266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "0     HOUSEHOLD    0.000000\n",
       "1     Christmas    0.000000\n",
       "2      Sporting    0.000003\n",
       "3     HOBBIES_1    0.000017\n",
       "4       NoEvent    0.000064\n",
       "5       HOBBIES    0.000166\n",
       "6     Religious    0.000224\n",
       "7        monfri    0.000297\n",
       "8       midweek    0.000358\n",
       "9      Cultural    0.000428\n",
       "10     National    0.000472\n",
       "11      FOODS_1    0.000478\n",
       "12         CA_4    0.000574\n",
       "13      snap_CA    0.001049\n",
       "14         TX_1    0.001356\n",
       "15         CA_1    0.001579\n",
       "16  HOUSEHOLD_2    0.002172\n",
       "17      snap_TX    0.002337\n",
       "18         TX_2    0.002349\n",
       "19      weekend    0.002387\n",
       "20         year    0.003186\n",
       "21         WI_3    0.004111\n",
       "22           WI    0.004487\n",
       "23         TX_3    0.006562\n",
       "24         wday    0.008980\n",
       "25    HOBBIES_2    0.011794\n",
       "26  HOUSEHOLD_1    0.011983\n",
       "27           TX    0.014334\n",
       "28      FOODS_2    0.014792\n",
       "29         CA_2    0.015304\n",
       "30         WI_1    0.015749\n",
       "31        month    0.016901\n",
       "32      snap_WI    0.021974\n",
       "33      FOODS_3    0.023086\n",
       "34         CA_3    0.026263\n",
       "35         WI_2    0.046776\n",
       "36           CA    0.062013\n",
       "37        FOODS    0.069010\n",
       "38            d    0.139118\n",
       "39   sell_price    0.467266"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "ax[0].barh(feature_imp.feature[30:], feature_imp.importance[30:])\n",
    "ax[0].set_title('Decision Tree')\n",
    "ax[0].set_xlabel('Importance')\n",
    "ax[1].barh(lr_feature_imp.feature[30:], lr_feature_imp.importance[30:])\n",
    "ax[1].set_title('Linear Regression')\n",
    "ax[1].set_xlabel('Coefficient')\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/featureimportance.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression\n",
    "Due to the size of the dataset we can only really use LinearSVR here, since our dataset is too large to make nonlinear SVR's viable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-eea102e8ac79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Initial try at SVR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvm_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msvm_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             epsilon=self.epsilon, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    922\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Initial try at SVR\n",
    "svm_reg = LinearSVR(epsilon=0.4, C=0.4, random_state=21)\n",
    "svm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LinearSVR(C=1.0, dual=True, epsilon=0.0,\n",
       "                                 fit_intercept=True, intercept_scaling=1.0,\n",
       "                                 loss='epsilon_insensitive', max_iter=1000,\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 0.4], 'epsilon': [0.2, 0.4]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search SVR\n",
    "parameters = {\n",
    "    'epsilon': [0.2, 0.4],\n",
    "    'C': [0.1, 0.4]\n",
    "}\n",
    "model = LinearSVR()\n",
    "clf = GridSearchCV(model, parameters, scoring='neg_mean_squared_error', cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.958821</td>\n",
       "      <td>0.025446</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.2}</td>\n",
       "      <td>-7.512782</td>\n",
       "      <td>-7.186471</td>\n",
       "      <td>-6.468062</td>\n",
       "      <td>-7.055773</td>\n",
       "      <td>0.436403</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.504628</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.4}</td>\n",
       "      <td>-7.554937</td>\n",
       "      <td>-7.220711</td>\n",
       "      <td>-6.494918</td>\n",
       "      <td>-7.090190</td>\n",
       "      <td>0.442483</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.982620</td>\n",
       "      <td>0.106887</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'C': 0.4, 'epsilon': 0.2}</td>\n",
       "      <td>-7.265266</td>\n",
       "      <td>-6.949928</td>\n",
       "      <td>-6.255557</td>\n",
       "      <td>-6.823585</td>\n",
       "      <td>0.421782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.143120</td>\n",
       "      <td>0.100372</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'C': 0.4, 'epsilon': 0.4}</td>\n",
       "      <td>-7.286887</td>\n",
       "      <td>-6.963951</td>\n",
       "      <td>-6.263851</td>\n",
       "      <td>-6.838230</td>\n",
       "      <td>0.427009</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       2.958821      0.025446         0.009581        0.000529     0.1   \n",
       "1       2.504628      0.010741         0.009673        0.001280     0.1   \n",
       "2       7.982620      0.106887         0.008579        0.000023     0.4   \n",
       "3       6.143120      0.100372         0.008617        0.000074     0.4   \n",
       "\n",
       "  param_epsilon                      params  split0_test_score  \\\n",
       "0           0.2  {'C': 0.1, 'epsilon': 0.2}          -7.512782   \n",
       "1           0.4  {'C': 0.1, 'epsilon': 0.4}          -7.554937   \n",
       "2           0.2  {'C': 0.4, 'epsilon': 0.2}          -7.265266   \n",
       "3           0.4  {'C': 0.4, 'epsilon': 0.4}          -7.286887   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0          -7.186471          -6.468062        -7.055773        0.436403   \n",
       "1          -7.220711          -6.494918        -7.090190        0.442483   \n",
       "2          -6.949928          -6.255557        -6.823585        0.421782   \n",
       "3          -6.963951          -6.263851        -6.838230        0.427009   \n",
       "\n",
       "   rank_test_score  \n",
       "0                3  \n",
       "1                4  \n",
       "2                1  \n",
       "3                2  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.4, 'epsilon': 0.2}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=0.4, dual=True, epsilon=0.2, fit_intercept=True,\n",
       "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "          random_state=22, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model with the best hyper-parameters\n",
    "svm_reg = LinearSVR(epsilon=0.2, C=0.4, random_state=22)\n",
    "svm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error CV: 6.787131686368653\n"
     ]
    }
   ],
   "source": [
    "#Cross validation scoring metric\n",
    "cv_score = cross_val_score(svm_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Mean Squared Error CV:\", -np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.775330130679082\n",
      "6.847785314466136\n"
     ]
    }
   ],
   "source": [
    "preds_train = svm_reg.predict(X_train)\n",
    "preds_test = svm_reg.predict(X_test)\n",
    "print(mean_squared_error(y_train, preds_train))\n",
    "print(mean_squared_error(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5933483357655558\n",
      "0.5997087616722856\n"
     ]
    }
   ],
   "source": [
    "#Coefficient of determination, R2\n",
    "print(svm_reg.score(X_train, y_train))\n",
    "print(svm_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21794484, -0.10626046,  6.24359455, ...,  0.02372039,\n",
       "        0.15304131,  0.29812693])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net\n",
    "Elastic Net is a linear regression model that incorporates both l1 and l2 regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, fit the model with default hyperparameters, alpha=1, l1_ratio=0.5. We can see that the MSE is much higher than for SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "           random_state=101, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = ElasticNet(alpha=1, l1_ratio = 0.5, random_state=101)\n",
    "en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error CV: 16.871055514922304\n"
     ]
    }
   ],
   "source": [
    "#Cross validation scoring metric\n",
    "cv_score_en = cross_val_score(en, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "print(\"Mean Squared Error CV:\", -np.mean(cv_score_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validated grid search over several potential hyperparameters. The best hyperparameter set found is alpha=0.1, l1_ratio=0.1. l1_ratio being close to zero suggests that the model does not like to suppress any/many features to zero coeff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                                  positive=False, precompute=False,\n",
       "                                  random_state=None, selection='cyclic',\n",
       "                                  tol=0.0001, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.1, 1, 10],\n",
       "                         'l1_ratio': [0.1, 0.25, 0.5, 0.75, 0.9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search SVR\n",
    "parameters_en = {\n",
    "    'alpha': [0.1, 1,10],\n",
    "    'l1_ratio': [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "}\n",
    "eNet = ElasticNet()\n",
    "en_gs = GridSearchCV(eNet, parameters_en, scoring='neg_mean_squared_error', cv=5)\n",
    "en_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'l1_ratio': 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit the final model using the best hyperparameter set, gives MSE of 15.35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.1,\n",
       "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "           random_state=102, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = ElasticNet(alpha=0.1, l1_ratio = 0.1, random_state=102)\n",
    "en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error CV: 14.682647916765845\n"
     ]
    }
   ],
   "source": [
    "#Cross validation scoring metric\n",
    "cv_score_en = cross_val_score(en, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "print(\"Mean Squared Error CV:\", -np.mean(cv_score_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
