{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import CleaningCars as cc\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove outliers...\n",
      "Remove outliers...\n",
      "Cleaned outliers !\n",
      "Imputed Missing Values\n",
      "One hot encodings done!\n",
      "Total Time:  7.21435885032018  minutes\n"
     ]
    }
   ],
   "source": [
    "df=cc.ultimateClean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Standardise features\n",
    "cols_to_norm = ['year','odometer','lat','long']\n",
    "\n",
    "df[cols_to_norm] = StandardScaler().fit_transform(df[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"price\",axis=1)\n",
    "y=df['price']\n",
    "\n",
    "#data_matrix=xgb.DMatrix(data=X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on train set: 2838661.113233323\n",
      "RMSE on train set: 1684.832666241168\n",
      "\n",
      "MSE on test set:  19441137.871776145\n",
      "RMSE on test set:  4409.2105724013845\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(learning_rate = 0.1, \n",
    "                           max_depth = 20, \n",
    "                           alpha = 10, \n",
    "                           n_estimators = 200)\n",
    "\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "preds_train= xgb_reg.predict(X_train)\n",
    "preds_test = xgb_reg.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"MSE on train set: {mean_squared_error(y_train, preds_train)}\")\n",
    "print(f\"RMSE on train set: {mean_squared_error(y_train, preds_train)**0.5}\")\n",
    "print()\n",
    "print(f\"MSE on test set:  {mean_squared_error(y_test, preds_test)}\")\n",
    "print(f\"RMSE on test set:  {mean_squared_error(y_test, preds_test)**0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1053\n",
      "[LightGBM] [Info] Number of data points in the train set: 310668, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 14235.128269\n",
      "MSE on train set: 1450707.5653418957\n",
      "RMSE on train set: 1204.4532225627925\n",
      "\n",
      "MSE on test set:  17791916.687488742\n",
      "RMSE on test set:  4218.046548757937\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "train_data=lgb.Dataset(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "lgbm_params={\"learning_rate\":0.1,\n",
    "             \"boosting_type\":\"gbdt\",  \n",
    "             \"objective\":\"regression\",\n",
    "             \"metric\":\"mse\",\n",
    "             \"num_leaves\":2000,\n",
    "             \"max_depth\":40}\n",
    "\n",
    "model=lgb.train(lgbm_params, train_data, 1000) \n",
    "preds_train=model.predict(X_train)\n",
    "preds_test=model.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"MSE on train set: {mean_squared_error(y_train, preds_train)}\")\n",
    "print(f\"RMSE on train set: {mean_squared_error(y_train, preds_train)**0.5}\")\n",
    "print()\n",
    "print(f\"MSE on test set:  {mean_squared_error(y_test, preds_test)}\")\n",
    "print(f\"RMSE on test set:  {mean_squared_error(y_test, preds_test)**0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
